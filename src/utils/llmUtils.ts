import { OpenAI } from 'openai';
import { streamResponse } from './chatUtils';
import { maskPII, getPIISummary } from './piiUtils';
import { isAPIQuestion } from './chatUtils';
import { HallucinationDetector, HallucinationMitigator } from './hallucinationDetector';

export const generateLLMResponse = async (
  question: string,
  onStream: (chunk: string) => void,
  onComplete?: () => void,
  signal?: AbortSignal
): Promise<void> => {
  try {
    // First check if this is an API question
    if (isAPIQuestion(question)) {
      onStream("I notice you're asking about an API. Please use the Knowledge Base mode to access API documentation and configurations. Switch to Knowledge Base mode using the toggle at the top of the chat.");
      onComplete?.();
      return;
    }

    const token = import.meta.env.VITE_OPENAI_API_KEY;

    if (!token) {
      throw new Error('OpenAI API key not found in environment variables');
    }

    try {
      // Check for PII in the question
      const piiSummary = getPIISummary(question);
      if (piiSummary.hasPII) {
        console.warn('PII detected in question:', piiSummary.types);
        // Mask PII before sending to OpenAI
        question = maskPII(question);
      }

      const openai = new OpenAI({
        apiKey: token,
        dangerouslyAllowBrowser: true
      });

      const response = await openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: 'You are a helpful AI assistant. Never ask for or encourage sharing of personal information. Always provide accurate information and clearly indicate when you are uncertain about something.'
          },
          {
            role: 'user',
            content: question
          }
        ],
        temperature: 0.7,
        max_tokens: 500,
        stream: false
      });

      if (response.choices && response.choices.length > 0) {
        let generatedText = response.choices[0].message.content || '';
        
        // **HALLUCINATION DETECTION - Example 3: Pure AI response validation**
        // Since this is pure AI mode without knowledge base context, we focus on
        // confidence and consistency checks
        const hallucinationResult = HallucinationDetector.detectHallucination(
          generatedText,
          [], // No knowledge base context in pure AI mode
          question,
          0.75 // Simulated confidence score for pure AI responses
        );

        console.log('Pure AI Response Hallucination Check:', hallucinationResult);

        // Apply mitigation strategies for pure AI responses
        if (hallucinationResult.isHallucination) {
          console.warn('Potential hallucination detected in pure AI response');
          
          // Add disclaimer for AI-generated content
          generatedText = `ü§ñ **AI-Generated Response**\n\n${generatedText}\n\n‚ö†Ô∏è *This response is generated by AI and should be verified independently. For more reliable information, try using Knowledge Base mode with verified sources.*`;
          
          // Apply uncertainty quantification
          if (hallucinationResult.confidence < 0.6) {
            generatedText = HallucinationMitigator.quantifyUncertainty(generatedText, 'high');
          } else if (hallucinationResult.confidence < 0.8) {
            generatedText = HallucinationMitigator.quantifyUncertainty(generatedText, 'medium');
          }
        } else {
          // Even for non-hallucinated responses, add AI disclaimer
          generatedText = `${generatedText}\n\n*This response is AI-generated. For verified information from your knowledge base, switch to Knowledge Base mode.*`;
        }
        
        // Check for PII in the response
        const responsePIISummary = getPIISummary(generatedText);
        if (responsePIISummary.hasPII) {
          console.warn('PII detected in response:', responsePIISummary.types);
          // Mask any PII in the response
          generatedText = maskPII(generatedText);
        }

        await streamResponse(generatedText, onStream, signal);
      } else {
        throw new Error('No response generated');
      }
    } catch (error: any) {
      if (error?.status === 401) {
        throw new Error('Invalid OpenAI API key');
      }
      
      if (error?.code === 'rate_limit_exceeded') {
        throw new Error('API rate limit exceeded. Please try again later.');
      }

      if (error?.status === 400) {
        throw new Error(`Bad Request: ${error.message || 'Invalid request parameters'}`);
      }

      if (error?.message === 'Failed to fetch') {
        throw new Error('Network error. Please check your internet connection and try again.');
      }

      throw error;
    }

    onComplete?.();
  } catch (error) {
    if (error instanceof Error) {
      if (error.message !== 'Request aborted') {
        onStream(`\nError: ${error.message}`);
      }
    } else {
      onStream('\nError: An unexpected error occurred');
    }
    onComplete?.();
    throw error;
  }
};